{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PEDESTRIAN DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[164, 158, 159],\n",
       "        [158, 153, 154],\n",
       "        [157, 153, 152],\n",
       "        ...,\n",
       "        [ 14,  24,  34],\n",
       "        [ 12,  17,  26],\n",
       "        [  3,   2,  11]],\n",
       "\n",
       "       [[164, 161, 157],\n",
       "        [165, 163, 155],\n",
       "        [163, 165, 153],\n",
       "        ...,\n",
       "        [ 17,  23,  36],\n",
       "        [  2,   3,  13],\n",
       "        [  6,   4,  10]],\n",
       "\n",
       "       [[161, 153, 164],\n",
       "        [157, 150, 157],\n",
       "        [158, 157, 153],\n",
       "        ...,\n",
       "        [  4,   8,  19],\n",
       "        [  4,   3,  13],\n",
       "        [ 16,   8,  18]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[138, 134, 129],\n",
       "        [142, 136, 131],\n",
       "        [142, 136, 131],\n",
       "        ...,\n",
       "        [183, 185, 186],\n",
       "        [158, 155, 164],\n",
       "        [129, 121, 138]],\n",
       "\n",
       "       [[140, 136, 131],\n",
       "        [144, 140, 135],\n",
       "        [152, 146, 139],\n",
       "        ...,\n",
       "        [189, 191, 192],\n",
       "        [164, 162, 168],\n",
       "        [135, 127, 144]],\n",
       "\n",
       "       [[150, 146, 141],\n",
       "        [150, 147, 139],\n",
       "        [149, 147, 137],\n",
       "        ...,\n",
       "        [190, 192, 193],\n",
       "        [168, 168, 174],\n",
       "        [139, 134, 149]]], dtype=uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = cv2.imread(r\"D:\\Visualcode\\DL\\Pedestrian_detection\\ped6.jpg\")\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image',input)\n",
    "cv2.waitKey(5000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=cv2.CascadeClassifier(r\"D:\\Visualcode\\DL\\Pedestrian_detection\\haarcascade_fullbody.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Pedestrian Detected:  12\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(r\"D:\\Visualcode\\DL\\Pedestrian_detection\\ped6.jpg\")\n",
    "\n",
    "def pedestrian_detection(frame):\n",
    "    gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    pedestrians=classifier.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=1)\n",
    "    total_detections=0\n",
    "    # Detection of rectangle\n",
    "    for (x, y, w, h) in pedestrians:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, 'Person', (x+5, y-5), font, 0.5, (0, 255, 0), 1)\n",
    "        total_detections +=1\n",
    "\n",
    "    # Processing the image with detections\n",
    "    cv2.imshow(\"Pedestrian Detection\", frame)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Total Pedestrian Detected: \", total_detections)\n",
    "    return frame\n",
    "\n",
    "output = pedestrian_detection(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pedestrian Detection in a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(r\"D:\\Visualcode\\DL\\Pedestrian_detection\\People_Walking.mp4\")\n",
    "while True:\n",
    "    success,frame=cap.read()\n",
    "    cv2.imshow('video',frame)\n",
    "    if cv2.waitKey(5)&0xFF==27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = cv2.CascadeClassifier(r\"D:\\Visualcode\\DL\\Pedestrian_detection\\haarcascade_fullbody.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(frame, cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m     16\u001b[0m \u001b[39m# Detecting pedestrians in the frame\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m pedestrians \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39;49mdetectMultiScale(gray, scaleFactor\u001b[39m=\u001b[39;49m\u001b[39m1.1\u001b[39;49m, minNeighbors\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, minSize\u001b[39m=\u001b[39;49m(\u001b[39m30\u001b[39;49m, \u001b[39m30\u001b[39;49m))\n\u001b[0;32m     20\u001b[0m \u001b[39m# Plotting rectangles around the detections\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39mfor\u001b[39;00m (x, y, w, h) \u001b[39min\u001b[39;00m pedestrians:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(r\"D:\\Visualcode\\DL\\Pedestrian_detection\\People_Walking.mp4\")\n",
    "ret, frame=cap.read()\n",
    "frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "# Define the codec and create a video writer object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "out = cv2.VideoWriter('output_video.avi', fourcc, 30,(frame_width, frame_height))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    # Break the loop if the video ends\n",
    "    if not ret:\n",
    "        break\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detecting pedestrians in the frame\n",
    "    pedestrians = classifier.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "\n",
    "    # Plotting rectangles around the detections\n",
    "    for (x, y, w, h) in pedestrians:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, 'Pedestrian', (x, y - 10),cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    out.write(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(frame, cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m     19\u001b[0m \u001b[39m# Detecting pedestrians in the frame\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m pedestrians \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39;49mdetectMultiScale(gray, scaleFactor\u001b[39m=\u001b[39;49m\u001b[39m1.1\u001b[39;49m, minNeighbors\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, minSize\u001b[39m=\u001b[39;49m(\u001b[39m30\u001b[39;49m, \u001b[39m30\u001b[39;49m))\n\u001b[0;32m     22\u001b[0m \u001b[39m# Increment the pedestrian counter for each detection\u001b[39;00m\n\u001b[0;32m     23\u001b[0m pedestrian_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(pedestrians)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(r\"D:\\Visualcode\\DL\\Pedestrian_detection\\People_Walking.mp4\")\n",
    "ret, frame = cap.read()\n",
    "frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "# Define the codec and create a video writer object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "out = cv2.VideoWriter('output_video.avi', fourcc, 30, (frame_width, frame_height))\n",
    "\n",
    "# Initialize a counter for the total number of pedestrians detected\n",
    "pedestrian_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    # Break the loop if the video ends\n",
    "    # if not ret:\n",
    "    #     break\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detecting pedestrians in the frame\n",
    "    pedestrians = classifier.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Increment the pedestrian counter for each detection\n",
    "    pedestrian_count += len(pedestrians)\n",
    "    \n",
    "    # Plotting rectangles around the detections\n",
    "    for (x, y, w, h) in pedestrians:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, 'Pedestrian', (x, y - 10),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the total number of pedestrians detected on the video\n",
    "    cv2.putText(frame, f'Total Pedestrian detections: {pedestrian_count}',(10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    out.write(frame)\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63963b3f4c440940f0b94a3100916033a226cb4f45979123153792d60aa56d6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
